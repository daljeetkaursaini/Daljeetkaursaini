{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdVkYBP1MwB/b7tCmHJWUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daljeetkaursaini/Daljeetkaursaini/blob/main/underwater_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pntd2NkoC5ad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage import data, color\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal as sig\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.util import img_as_ubyte, img_as_float64\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.color import rgb2hsv\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "HURQ6SjhDxrX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import skimage\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "import matplotlib\n",
        "from matplotlib import pyplot\n",
        "import sys\n",
        "import PIL\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "WcBc-s-6D_jT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import glob\n",
        "import os\n"
      ],
      "metadata": {
        "id": "zBgqRIP4ER5d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "from math import log2, log10\n",
        "def mu_a(x, alpha_L=0.1, alpha_R=0.1):\n",
        "    \"\"\"\n",
        "      Calculates the asymetric alpha-trimmed mean\n",
        "    \"\"\"\n",
        "    # sort pixels by intensity - for clipping\n",
        "    x = sorted(x)\n",
        "    # get number of pixels\n",
        "    K = len(x)\n",
        "    # calculate T alpha L and T alpha R\n",
        "    T_a_L = math.ceil(alpha_L*K)\n",
        "    T_a_R = math.floor(alpha_R*K)\n",
        "    # calculate mu_alpha weight\n",
        "    weight = (1/(K-T_a_L-T_a_R))\n",
        "    # loop through flattened image starting at T_a_L+1 and ending at K-T_a_R\n",
        "    s   = int(T_a_L+1)\n",
        "    e   = int(K-T_a_R)\n",
        "    val = sum(x[s:e])\n",
        "    val = weight*val\n",
        "    return val\n"
      ],
      "metadata": {
        "id": "DZtD3CFxEYjG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def s_a(x, mu):\n",
        "    val = 0\n",
        "    for pixel in x:\n",
        "        val += math.pow((pixel-mu), 2)\n",
        "    return val/len(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "_q1lCHNiE3Di"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _uicm(x):\n",
        "    R = x[:,:,0].flatten()\n",
        "    G = x[:,:,1].flatten()\n",
        "    B = x[:,:,2].flatten()\n",
        "    RG = R-G\n",
        "    YB = ((R+G)/2)-B\n",
        "    mu_a_RG = mu_a(RG)\n",
        "    mu_a_YB = mu_a(YB)\n",
        "    s_a_RG = s_a(RG, mu_a_RG)\n",
        "    s_a_YB = s_a(YB, mu_a_YB)\n",
        "    l = math.sqrt( (math.pow(mu_a_RG,2)+math.pow(mu_a_YB,2)) )\n",
        "    r = math.sqrt(s_a_RG+s_a_YB)\n",
        "    return (-0.0268*l)+(0.1586*r)\n",
        "\n"
      ],
      "metadata": {
        "id": "EYnYstA4E9pm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sobel(x):\n",
        "    dx = ndimage.sobel(x,0)\n",
        "    dy = ndimage.sobel(x,1)\n",
        "    mag = np.hypot(dx, dy)\n",
        "    mag *= 255.0 / np.max(mag) \n",
        "    return mag\n"
      ],
      "metadata": {
        "id": "gavuU_zkFB8d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eme(x, window_size):\n",
        "    \"\"\"\n",
        "      Enhancement measure estimation\n",
        "      x.shape[0] = height\n",
        "      x.shape[1] = width\n",
        "    \"\"\"\n",
        "    # if 4 blocks, then 2x2...etc.\n",
        "    k1 = x.shape[1]/window_size\n",
        "    k2 = x.shape[0]/window_size\n",
        "    # weight\n",
        "    w = 2./(k1*k2)\n",
        "    blocksize_x = window_size\n",
        "    blocksize_y = window_size\n",
        "    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n",
        "    x = x[:int(blocksize_y*k2), :int(blocksize_x*k1)]\n",
        "    val = 0\n",
        "    for l in range(int(k1)):\n",
        "        for k in range(int(k2)):\n",
        "            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1)]\n",
        "            max_ = np.max(block)\n",
        "            min_ = np.min(block)\n",
        "            # bound checks, can't do log(0)\n",
        "            if min_ == 0.0: val += 0\n",
        "            elif max_ == 0.0: val += 0\n",
        "            else: val += math.log(max_/min_)\n",
        "    return w*val\n"
      ],
      "metadata": {
        "id": "3LljnPipFG8c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _uism(x):\n",
        "    \"\"\"\n",
        "      Underwater Image Sharpness Measure\n",
        "    \"\"\"\n",
        "    # get image channels\n",
        "    R = x[:,:,0]\n",
        "    G = x[:,:,1]\n",
        "    B = x[:,:,2]\n",
        "    # first apply Sobel edge detector to each RGB component\n",
        "    Rs = sobel(R)\n",
        "    Gs = sobel(G)\n",
        "    Bs = sobel(B)\n",
        "    # multiply the edges detected for each channel by the channel itself\n",
        "    R_edge_map = np.multiply(Rs, R)\n",
        "    G_edge_map = np.multiply(Gs, G)\n",
        "    B_edge_map = np.multiply(Bs, B)\n",
        "    # get eme for each channel\n",
        "    r_eme = eme(R_edge_map, 10)\n",
        "    g_eme = eme(G_edge_map, 10)\n",
        "    b_eme = eme(B_edge_map, 10)\n",
        "    # coefficients\n",
        "    lambda_r = 0.299\n",
        "    lambda_g = 0.587\n",
        "    lambda_b = 0.144\n",
        "    return (lambda_r*r_eme) + (lambda_g*g_eme) + (lambda_b*b_eme)\n"
      ],
      "metadata": {
        "id": "WcTQFGx2FQvS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plip_g(x,mu=1026.0):\n",
        "    return mu-x\n",
        "\n"
      ],
      "metadata": {
        "id": "xTH3oGwCFX5J"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plip_theta(g1, g2, k):\n",
        "    g1 = plip_g(g1)\n",
        "    g2 = plip_g(g2)\n",
        "    return k*((g1-g2)/(k-g2))\n",
        "\n",
        "def plip_cross(g1, g2, gamma):\n",
        "    g1 = plip_g(g1)\n",
        "    g2 = plip_g(g2)\n",
        "    return g1+g2-((g1*g2)/(gamma))\n",
        "\n",
        "def plip_diag(c, g, gamma):\n",
        "    g = plip_g(g)\n",
        "    return gamma - (gamma * math.pow((1 - (g/gamma) ), c) )\n",
        "\n",
        "def plip_multiplication(g1, g2):\n",
        "    return plip_phiInverse(plip_phi(g1) * plip_phi(g2))\n",
        "    #return plip_phiInverse(plip_phi(plip_g(g1)) * plip_phi(plip_g(g2)))\n",
        "\n",
        "def plip_phiInverse(g):\n",
        "    plip_lambda = 1026.0\n",
        "    plip_beta   = 1.0\n",
        "    return plip_lambda * (1 - math.pow(math.exp(-g / plip_lambda), 1 / plip_beta));\n",
        "\n",
        "def plip_phi(g):\n",
        "    plip_lambda = 1026.0\n",
        "    plip_beta   = 1.0\n",
        "    return -plip_lambda * math.pow(math.log(1 - g / plip_lambda), plip_beta)\n"
      ],
      "metadata": {
        "id": "MHmzEXKgFb-b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _uiconm(x, window_size):\n",
        "    plip_lambda = 1026.0\n",
        "    plip_gamma  = 1026.0\n",
        "    plip_beta   = 1.0\n",
        "    plip_mu     = 1026.0\n",
        "    plip_k      = 1026.0\n",
        "    # if 4 blocks, then 2x2...etc.\n",
        "    k1 = x.shape[1]/window_size\n",
        "    k2 = x.shape[0]/window_size\n",
        "    # weight\n",
        "    w = -1./(k1*k2)\n",
        "    blocksize_x = window_size\n",
        "    blocksize_y = window_size\n",
        "    # make sure image is divisible by window_size - doesn't matter if we cut out some pixels\n",
        "    x = x[:int(blocksize_y*k2), :int(blocksize_x*k1)]\n",
        "    # entropy scale - higher helps with randomness\n",
        "    alpha = 1\n",
        "    val = 0\n",
        "    for l in range(int(k1)):\n",
        "        for k in range(int(k2)):\n",
        "            block = x[k*window_size:window_size*(k+1), l*window_size:window_size*(l+1), :]\n",
        "            max_ = np.max(block)\n",
        "            min_ = np.min(block)\n",
        "            top = max_-min_\n",
        "            bot = max_+min_\n",
        "            if math.isnan(top) or math.isnan(bot) or bot == 0.0 or top == 0.0: val += 0.0\n",
        "            else: val += alpha*math.pow((top/bot),alpha) * math.log(top/bot)\n",
        "            #try: val += plip_multiplication((top/bot),math.log(top/bot))\n",
        "    return w*val\n"
      ],
      "metadata": {
        "id": "LLU6Qf7iFiSp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getUIQM(x):\n",
        "    \"\"\"\n",
        "      Function to return UIQM to be called from other programs\n",
        "      x: image\n",
        "    \"\"\"\n",
        "    x = x.astype(np.float32)\n",
        "    ### from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7300447\n",
        "    #c1 = 0.4680; c2 = 0.2745; c3 = 0.2576\n",
        "    ### from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7300447\n",
        "    c1 = 0.0282; c2 = 0.2953; c3 = 3.5753\n",
        "    uicm   = _uicm(x)\n",
        "    uism   = _uism(x)\n",
        "    uiconm = _uiconm(x, 10)\n",
        "    uiqm = (c1*uicm) + (c2*uism) + (c3*uiconm)\n",
        "    return uiqm\n"
      ],
      "metadata": {
        "id": "3epuctw1Fqlp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UCIQE(rgb_in):\n",
        "    # calculate Chroma\n",
        "    rgb_in = cv2.normalize(rgb_in, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    (l,a,b)=cv2.split(rgb_in)\n",
        "    Chroma = np.sqrt(a*a + b*b)\n",
        "    StdVarianceChroma = np.std(np.reshape(Chroma[:,:],(-1,1)))\n",
        "\n",
        "    hsv = skimage.color.rgb2hsv(rgb_in)\n",
        "    Saturation = hsv[:,:,2]\n",
        "    MeanSaturation = np.mean(np.reshape(Saturation[:,:],(-1,1)))\n",
        "\n",
        "    ContrastLuminance = max(np.reshape(l[:,:],(-1,1))) - min(np.reshape(l[:,:],(-1,1)))\n",
        "    UCIQE = 0.4680 * StdVarianceChroma + 0.2745 * ContrastLuminance + 0.2576 * MeanSaturation\n",
        "    return float(UCIQE)\n",
        "\n",
        "def improve_contrast_image_using_clahe(bgr_image):\n",
        "    hsv = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
        "    hsv_planes = cv2.split(hsv)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    hsv_planes[2] = clahe.apply(hsv_planes[2])\n",
        "    hsv = cv2.merge(hsv_planes)\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n"
      ],
      "metadata": {
        "id": "H50YVyZfFsRZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal as sig\n",
        "import math\n",
        "from skimage.util import img_as_ubyte, img_as_float64\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.color import rgb2hsv\n",
        "\n",
        "\n",
        "''' Generates guided filter''' \n",
        "def guide(I,P,r,e):\n",
        "\n",
        "    h,w=np.shape(I)\n",
        "    window = np.ones((r,r))/(r*r)\n",
        "\n",
        "    meanI = sig.convolve2d(I, window,mode='same')\n",
        "    meanP = sig.convolve2d(P, window,mode='same')\n",
        "\n",
        "    corrI = sig.convolve2d(I*I, window,mode='same')\n",
        "    corrIP = sig.convolve2d(I*P, window,mode='same')\n",
        "\n",
        "    varI = corrI - meanI*meanI\n",
        "    covIP = corrIP - meanI*meanP\n",
        "    a = covIP/(varI+e)\n",
        "    b = meanP - a*meanI\n",
        "\n",
        "    meana = sig.convolve2d(a, window,mode='same')\n",
        "    meanb = sig.convolve2d(b, window,mode='same')\n",
        "\n",
        "    q = meana*I+meanb\n",
        "\n",
        "    return q\n"
      ],
      "metadata": {
        "id": "V4-56ESHF3kf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def localmin(D, r=15):\n",
        "    R = int(r/2)\n",
        "    imax = D.shape[0]\n",
        "    jmax = D.shape[1]\n",
        "    LM = np.zeros([imax,jmax])\n",
        "    for i in np.arange(D.shape[0]):\n",
        "        for j in np.arange(D.shape[1]):\n",
        "            iL = np.max([i-R,0])\n",
        "            iR = np.min([i+R, imax])\n",
        "            jT = np.max([j-R,0])\n",
        "            jB = np.min([j+R, jmax])\n",
        "            # print(D[iL:iR+1,jT:jB+1].shape)\n",
        "            LM[i,j] = np.min(D[iL:iR+1,jT:jB+1])\n",
        "    return LM\n",
        "\n",
        "''' It will Apply guided filter to the images and removes haze''' \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jlmOcfb2F4__",
        "outputId": "cd5498ec-7c0f-4cca-d2c5-d318c03b20ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' It will Apply guided filter to the images and removes haze'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocessing(GD, I,V):\n",
        "    # this will give indices of the columnised image GD\n",
        "    flat_indices = np.argsort(GD, axis=None)\n",
        "    R,C = GD.shape\n",
        "    top_indices_flat = flat_indices[ int(np.round(0.999*R*C)):: ]\n",
        "    top_indices = np.unravel_index(top_indices_flat, GD.shape)\n",
        "\n",
        "    max_v_index = np.unravel_index( np.argmax(V[top_indices], axis=None), V.shape )\n",
        "    I = I/255.0\n",
        "    A = I[max_v_index[0], max_v_index[1], :]\n",
        "\n",
        "    beta = 1.0\n",
        "    transmission = np.minimum( np.maximum(np.exp(-1*beta*GD), 0.1) , 0.9)\n",
        "    # transmission = np.exp(-1*beta*GD)\n",
        "    transmission3 = np.zeros(I.shape)\n",
        "    transmission3[:,:,0] = transmission\n",
        "    transmission3[:,:,1] = transmission\n",
        "    transmission3[:,:,2] = transmission\n",
        "\n",
        "    J = A + (I - A)/transmission3\n",
        "    J = J - np.min(J)\n",
        "    J = J/np.max(J)\n",
        "    return J\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IsFV49kaF96p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dehaze(img):\n",
        "    # Read the Image\n",
        "    #img = cv2.imread(\"vit.jpg\")\n",
        "    # opencv reads any image in Blue-Green-Red(BGR) format,\n",
        "    # so change it to RGB format, which is popular.\n",
        "    I = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # Split Image to Hue-Saturation-Value(HSV) format.\n",
        "    H,S,V = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV) )\n",
        "    V = V/255.0\n",
        "    S = S/255.0\n",
        "\n",
        "    # Calculating Depth Map using the linear model fit by ZHU et al.\n",
        "    theta_0 = 0.121779\n",
        "    theta_1 = 0.959710\n",
        "    theta_2 = -0.780245\n",
        "    sigma   = 0.041337\n",
        "    epsilon = np.random.normal(0, sigma, H.shape )\n",
        "    D = theta_0 + theta_1*V + theta_2*S + epsilon\n",
        "\n",
        "    # Local Minima of Depth map\n",
        "    LMD = localmin(D, 15)\n",
        "\n",
        "    r = 8; # try r=2, 4, 8 or 18\n",
        "    eps = 0.2 * 0.2; # try eps=0.1^2, 0.2^2, 0.4^2\n",
        "        # eps *= 255 * 255;   # Because the intensity range of our images is [0, 255]\n",
        "    GD=guide(D,LMD,r,eps)\n",
        "\n",
        "    J = postprocessing(GD, I,V)\n",
        "    return J\n"
      ],
      "metadata": {
        "id": "ryY70DJXGEIT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip(image=None):\n",
        "    if image is None:\n",
        "        return None\n",
        "    image[image < 0] = 0\n",
        "    image[image > 1] = 1\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "fenzWvpRGMPI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def white_balance(img):\n",
        "    image = img_as_float64(img)\n",
        "\n",
        "            # Extract colour channels\n",
        "    R = image[:, :, 2]\n",
        "    G = image[:, :, 1]\n",
        "    B = image[:, :, 0]\n",
        "\n",
        "            # Obtain average intensity for each colour channel\n",
        "    mean_R = np.mean(R)\n",
        "    mean_G = np.mean(G)\n",
        "    mean_B = np.mean(B)\n",
        "\n",
        "    mean_RGB = np.array([mean_R, mean_G, mean_B])\n",
        "\n",
        "            # Obtain scaling factor\n",
        "    grayscale = np.mean(mean_RGB)\n",
        "    scale = grayscale / mean_RGB\n",
        "\n",
        "    white_balanced = np.zeros(image.shape)\n",
        "\n",
        "            # Rescale original intensities\n",
        "    white_balanced[:, :, 2] = scale[0] * R\n",
        "    white_balanced[:, :, 1] = scale[1] * G\n",
        "    white_balanced[:, :, 0] = scale[2] * B\n",
        "\n",
        "            # Clip to [0.0, 1.0]\n",
        "    white_balanced = clip(white_balanced)\n",
        "    return white_balanced\n",
        "''' equlises the rgb chanells of the image using histograms ''' \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3AvdHl-_GPWH",
        "outputId": "619366f9-191e-43a3-d3bd-97f7af66823f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' equlises the rgb chanells of the image using histograms '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simplest_cb(image, percent):\n",
        "    if image is None:\n",
        "        return None\n",
        "    out_channels = []\n",
        "    channels = cv2.split(image)\n",
        "    totalstop = channels[0].shape[0] * channels[0].shape[1] * percent / 200.0\n",
        "    for channel in channels:\n",
        "        bc = cv2.calcHist([channel], [0], None, [256], (0,256), accumulate=False)\n",
        "        lv = np.searchsorted(np.cumsum(bc), totalstop)\n",
        "        hv = 255-np.searchsorted(np.cumsum(bc[::-1]), totalstop)\n",
        "        lut = np.array([0 if i < lv else (255 if i > hv else round(float(i-lv)/float(hv-lv)*255)) for i in np.arange(0, 256)], dtype=\"uint8\")\n",
        "        out_channels.append(cv2.LUT(channel, lut))\n",
        "    k = cv2.merge(out_channels)\n",
        "    #k = cv2.cvtColor(k, cv2.COLOR_BGR2RGB)    \n",
        "    return k\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rjz9PgwTGT95"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def luminance_map(image=None):\n",
        "    if image is None:\n",
        "        return None\n",
        "    '''Function to generate the Luminance Weight Map of an image'''\n",
        "        # Validate parameters\n",
        "        \n",
        "    image = img_as_float64(image)\n",
        "\n",
        "        # Generate Luminance Map\n",
        "    luminance = np.mean(image, axis=2)\n",
        "    luminancemap = np.sqrt((1 / 3) * (np.square(image[:, :, 0] - luminance + np.square(image[:, :, 1] - luminance) \n",
        "                                                + np.square(image[:, :, 2] - luminance))))\n",
        "    return luminancemap\n",
        "\n"
      ],
      "metadata": {
        "id": "OeqSAtPmGkAv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chromatic_map(image=None):\n",
        "    if image is None:\n",
        "        return None\n",
        "    '''Function to generate the Chromatic Weight Map of an image'''\n",
        "        # Validate parameters\n",
        "        \n",
        "    image = img_as_float64(image)\n",
        "        \n",
        "        # Convert to HSV colour space\n",
        "    hsv = rgb2hsv(image)\n",
        "\n",
        "        # Extract Saturation\n",
        "    saturation = hsv[:, :, 1]\n",
        "    max_saturation = 1.0\n",
        "    sigma = 0.3\n",
        "        \n",
        "        # Generate Chromatic Map\n",
        "    chromaticmap = np.exp(-1 * (((saturation - max_saturation) ** 2) / (2 * (sigma ** 2))))\n",
        "    return chromaticmap\n",
        "\n"
      ],
      "metadata": {
        "id": "dJwQ29ymGlhN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saliency_map(image=None):\n",
        "    if image is None:\n",
        "        return None\n",
        "    '''Function to generate the Saliency Weight Map of an image'''\n",
        "        # Validate parameters   \n",
        "    image = img_as_float64(image)\n",
        "        \n",
        "        # Convert image to grayscale\n",
        "    if(len(image.shape) > 2):\n",
        "        image = rgb2gray(image)\n",
        "    else:\n",
        "        image = image\n",
        "        \n",
        "        # Apply Gaussian Smoothing\n",
        "    gaussian = cv2.GaussianBlur(image,(5, 5),0) \n",
        "        \n",
        "        # Apply Mean Smoothing\n",
        "    image_mean = np.mean(image)\n",
        "        \n",
        "        # Generate Saliency Map\n",
        "    saliencymap = np.absolute(gaussian - image_mean)\n",
        "    return saliencymap\n",
        "\n"
      ],
      "metadata": {
        "id": "8CsowEBEGqXk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def image_pyramid(image=None, pyramid_type='gaussian', levels=1):\n",
        "    if image is None:\n",
        "        return None\n",
        "        '''Function to generate the Gaussian/Laplacian pyramid of an image'''\n",
        "        # Validate parameters\n",
        "    image = img_as_float64(image)\n",
        "        \n",
        "        # Generate Gaussian Pyramid\n",
        "    current_layer = image\n",
        "    gaussian = [current_layer]\n",
        "    for i in range(levels):\n",
        "        current_layer = cv2.pyrDown(current_layer)\n",
        "        gaussian.append(current_layer)\n",
        "            \n",
        "    if pyramid_type == 'gaussian':\n",
        "        return gaussian\n",
        "        # Generate Laplacian Pyramid\n",
        "    elif pyramid_type == 'laplacian':\n",
        "        current_layer = gaussian[levels-1]\n",
        "        laplacian = [current_layer]\n",
        "        for i in range(levels - 1, 0, -1):\n",
        "            shape = (gaussian[i-1].shape[1], gaussian[i-1].shape[0])\n",
        "            expand_gaussian = cv2.pyrUp(gaussian[i], dstsize=shape)\n",
        "            current_layer = cv2.subtract(gaussian[i-1], expand_gaussian)\n",
        "            laplacian.append(current_layer)\n",
        "        laplacian.reverse()\n",
        "        return laplacian\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "Y4APzpVaGuKv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_maps(J,white_balanced):\n",
        "    input_images = [\n",
        "            img_as_float64(J),\n",
        "            img_as_float64(white_balanced)\n",
        "        ]\n",
        "\n",
        "    weight_maps = [\n",
        "                # Weight maps for first image\n",
        "                {\n",
        "                    'luminance': luminance_map(image=input_images[0]),\n",
        "                    'chromatic': chromatic_map(image=input_images[0]),\n",
        "                    'saliency': saliency_map(image=input_images[0])\n",
        "                },\n",
        "\n",
        "                # Weight maps for second image\n",
        "                {\n",
        "                    'luminance': luminance_map(image=input_images[1]),\n",
        "                    'chromatic': chromatic_map(image=input_images[1]),\n",
        "                    'saliency': saliency_map(image=input_images[1])\n",
        "                }\n",
        "            ]\n",
        "    weight_maps[0]['combined'] = (weight_maps[0]['luminance'] * weight_maps[0]['chromatic'] * weight_maps[0]['saliency'])\n",
        "    weight_maps[1]['combined'] = (weight_maps[1]['luminance'] * weight_maps[1]['chromatic'] * weight_maps[1]['saliency'])\n",
        "\n",
        "            # Normalized weight maps\n",
        "    weight_maps[0]['normalized'] = weight_maps[0]['combined'] / (weight_maps[0]['combined'] + weight_maps[1]['combined'])\n",
        "    weight_maps[1]['normalized'] = weight_maps[1]['combined'] / (weight_maps[0]['combined'] + weight_maps[1]['combined'])\n",
        "    \n",
        "    pyramid_height=12\n",
        "    gaussians = [\n",
        "            image_pyramid(image=weight_maps[0]['normalized'], pyramid_type='gaussian', levels=pyramid_height),\n",
        "            image_pyramid(image=weight_maps[1]['normalized'], pyramid_type='gaussian', levels=pyramid_height)\n",
        "        ]\n",
        "    l=[input_images,weight_maps,gaussians]\n",
        "    return l\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JOG4JV6PGycw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fusion(inputs=None, weights=None, gaussians=None):\n",
        "    if inputs is None or weights is None or gaussians is None:\n",
        "        return None\n",
        "        '''Function to fuse the pyramids together'''\n",
        "        # Validate parameters\n",
        "    fused_levels = []\n",
        "\n",
        "        # Perform Fusion by combining the Laplacian and Gaussian pyramids\n",
        "    for i in range(len(gaussians[0])):\n",
        "        if len(inputs[0].shape) > 2:\n",
        "            for j in range(inputs[0].shape[2]):\n",
        "                laplacians = [\n",
        "                        image_pyramid(image=inputs[0][:, :, j], pyramid_type='laplacian', levels=len(gaussians[0])),\n",
        "                        image_pyramid(image=inputs[1][:, :, j], pyramid_type='laplacian', levels=len(gaussians[0]))\n",
        "                             ]\n",
        "                    # Adjust rows to match\n",
        "                row_size = np.min(np.array([\n",
        "                        laplacians[0][i].shape[0],\n",
        "                        laplacians[1][i].shape[0],\n",
        "                        gaussians[0][i].shape[0],\n",
        "                        gaussians[1][i].shape[0]\n",
        "                    ]))\n",
        "\n",
        "                    # Adjust columns to match\n",
        "                col_size = np.min(np.array([\n",
        "                        laplacians[0][i].shape[1],\n",
        "                        laplacians[1][i].shape[1],\n",
        "                        gaussians[0][i].shape[1],\n",
        "                        gaussians[1][i].shape[1]\n",
        "                    ]))\n",
        "                    \n",
        "                if j == 0:\n",
        "                    intermediate = np.ones(inputs[0][:row_size, :col_size].shape)\n",
        "                    # Fusion Step\n",
        "                intermediate[:, :, j] = (laplacians[0][i][:row_size, :col_size] * gaussians[0][i][:row_size, :col_size]) + (laplacians[1][i][:row_size, :col_size] * gaussians[1][i][:row_size, :col_size])\n",
        "            fused_levels.append(intermediate)\n",
        "        \n",
        "        # Reconstruct Image Pyramids\n",
        "    for i in range(len(fused_levels)-2, -1, -1):\n",
        "        level_1 = cv2.pyrUp(fused_levels[i+1])\n",
        "        level_2 = fused_levels[i]\n",
        "        r = min(level_1.shape[0], level_2.shape[0])\n",
        "        c = min(level_1.shape[1], level_2.shape[1])\n",
        "        fused_levels[i] = level_1[:r, :c] + level_2[:r, :c]\n",
        "\n",
        "        # Clip fused image to [0.0, 1.0]\n",
        "    fused = clip(fused_levels[0])\n",
        "    return fused\n",
        "\n"
      ],
      "metadata": {
        "id": "kht2tqoBG2lk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_contrast(image=None):\n",
        "        '''Function to enhance contrast in an image'''\n",
        "        # Validate parameters\n",
        "        if image is None:\n",
        "            return None\n",
        "\n",
        "        image = img_as_float64(image)\n",
        "\n",
        "        # Extract colour channels\n",
        "        R = image[:, :, 2]\n",
        "        G = image[:, :, 1]\n",
        "        B = image[:, :, 0]\n",
        "\n",
        "        # Obtain luminance using predefined scale factors\n",
        "        luminance = 0.299 * R + 0.587 * G + 0.114 * B\n",
        "        mean_luminance = np.mean(luminance)\n",
        "\n",
        "        # Compute scale factor\n",
        "        gamma = 2 * (0.5 + mean_luminance)\n",
        "\n",
        "        # Scale mean-luminance subtracted colour chanels \n",
        "        enhanced = np.zeros(image.shape)\n",
        "        enhanced[:, :, 2] = gamma * (R - mean_luminance)\n",
        "        enhanced[:, :, 1] = gamma * (G - mean_luminance)\n",
        "        enhanced[:, :, 0] = gamma * (B - mean_luminance)\n",
        "\n",
        "        # Clip to [0.0, 1.0]\n",
        "        enhanced = clip(enhanced)\n",
        "\n",
        "        return enhanced\n"
      ],
      "metadata": {
        "id": "RwSi8KlkG_6g"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import scipy, scipy.misc, scipy.signal\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import natsort\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def computeTextureWeights(fin, sigma, sharpness):\n",
        "    dt0_v = np.vstack((np.diff(fin, n=1, axis=0), fin[0,:]-fin[-1,:]))\n",
        "    dt0_h = np.vstack((np.diff(fin, n=1, axis=1).conj().T, fin[:,0].conj().T-fin[:,-1].conj().T)).conj().T\n",
        "\n",
        "    gauker_h = scipy.signal.convolve2d(dt0_h, np.ones((1,sigma)), mode='same')\n",
        "    gauker_v = scipy.signal.convolve2d(dt0_v, np.ones((sigma,1)), mode='same')\n",
        "\n",
        "    W_h = 1/(np.abs(gauker_h)*np.abs(dt0_h)+sharpness)\n",
        "    W_v = 1/(np.abs(gauker_v)*np.abs(dt0_v)+sharpness)\n",
        "\n",
        "    return  W_h, W_v\n",
        "    \n"
      ],
      "metadata": {
        "id": "MbzFbfGYHBU_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solveLinearEquation(IN, wx, wy, lamda):\n",
        "    [r, c] = IN.shape\n",
        "    k = r * c\n",
        "    dx =  -lamda * wx.flatten('F')\n",
        "    dy =  -lamda * wy.flatten('F')\n",
        "    tempx = np.roll(wx, 1, axis=1)\n",
        "    tempy = np.roll(wy, 1, axis=0)\n",
        "    dxa = -lamda *tempx.flatten('F')\n",
        "    dya = -lamda *tempy.flatten('F')\n",
        "    tmp = wx[:,-1]\n",
        "    tempx = np.concatenate((tmp[:,None], np.zeros((r,c-1))), axis=1)\n",
        "    tmp = wy[-1,:]\n",
        "    tempy = np.concatenate((tmp[None,:], np.zeros((r-1,c))), axis=0)\n",
        "    dxd1 = -lamda * tempx.flatten('F')\n",
        "    dyd1 = -lamda * tempy.flatten('F')\n",
        "    \n",
        "    wx[:,-1] = 0\n",
        "    wy[-1,:] = 0\n",
        "    dxd2 = -lamda * wx.flatten('F')\n",
        "    dyd2 = -lamda * wy.flatten('F')\n",
        "    \n",
        "    Ax = scipy.sparse.spdiags(np.concatenate((dxd1[:,None], dxd2[:,None]), axis=1).T, np.array([-k+r,-r]), k, k)\n",
        "    Ay = scipy.sparse.spdiags(np.concatenate((dyd1[None,:], dyd2[None,:]), axis=0), np.array([-r+1,-1]), k, k)\n",
        "    D = 1 - ( dx + dy + dxa + dya)\n",
        "    A = ((Ax+Ay) + (Ax+Ay).conj().T + scipy.sparse.spdiags(D, 0, k, k)).T\n",
        "    \n",
        "    tin = IN[:,:]\n",
        "    tout = scipy.sparse.linalg.spsolve(A, tin.flatten('F'))\n",
        "    OUT = np.reshape(tout, (r, c), order='F')\n",
        "    \n",
        "    return OUT\n",
        "    \n"
      ],
      "metadata": {
        "id": "WPgOPrz0HHbE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tsmooth(img, lamda=0.01, sigma=3.0, sharpness=0.001):\n",
        "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    x = np.copy(I)\n",
        "    wx, wy = computeTextureWeights(x, sigma, sharpness)\n",
        "    S = solveLinearEquation(I, wx, wy, lamda)\n",
        "    return S\n",
        "\n",
        "def rgb2gm(I):\n",
        "    if (I.shape[2] == 3):\n",
        "        I = cv2.normalize(I.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "        I = np.abs((I[:,:,0]*I[:,:,1]*I[:,:,2]))**(1/3)\n",
        "\n",
        "    return I\n",
        "\n",
        "def applyK(I, k, a=-0.3293, b=1.1258):\n",
        "    f = lambda x: np.exp((1-x**a)*b)\n",
        "    beta = f(k)\n",
        "    gamma = k**a\n",
        "    J = (I**gamma)*beta\n",
        "    return J\n",
        "\n",
        "def entropy(X):\n",
        "    tmp = X * 255\n",
        "    tmp[tmp > 255] = 255\n",
        "    tmp[tmp<0] = 0\n",
        "    tmp = tmp.astype(np.uint8)\n",
        "    _, counts = np.unique(tmp, return_counts=True)\n",
        "    pk = np.asarray(counts)\n",
        "    pk = 1.0*pk / np.sum(pk, axis=0)\n",
        "    S = -np.sum(pk * np.log2(pk), axis=0)\n",
        "    return S\n",
        "\n",
        "def maxEntropyEnhance(I, isBad, a=-0.3293, b=1.1258):\n",
        "    # Esatimate k\n",
        "    tmp = cv2.resize(I, (50,50), interpolation=cv2.INTER_AREA)\n",
        "    tmp[tmp<0] = 0\n",
        "    tmp = tmp.real\n",
        "    Y = rgb2gm(tmp)\n",
        "    \n",
        "    isBad = isBad * 1\n",
        "    isBad = scipy.misc.imresize(isBad, (50,50), interp='bicubic', mode='F')\n",
        "    isBad[isBad<0.5] = 0\n",
        "    isBad[isBad>=0.5] = 1\n",
        "    Y = Y[isBad==1]\n",
        "    \n",
        "    if Y.size == 0:\n",
        "       J = I\n",
        "       return J\n",
        "    \n",
        "    f = lambda k: -entropy(applyK(Y, k))\n",
        "    opt_k = scipy.optimize.fminbound(f, 1, 7)\n",
        "    \n",
        "    # Apply k\n",
        "    J = applyK(I, opt_k, a, b) - 0.01\n",
        "    return J\n"
      ],
      "metadata": {
        "id": "VLJhHn-iHNE_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exposer_fusion(img, mu=0.5, a=-0.3293, b=1.1258):\n",
        "    lamda = 0.5\n",
        "    sigma = 5\n",
        "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n",
        "    # Weight matrix estimation\n",
        "    t_b = np.max(I, axis=2)\n",
        "    t_our = cv2.resize(tsmooth(scipy.misc.imresize(t_b, 0.5, interp='bicubic', mode='F'), lamda, sigma), (t_b.shape[1], t_b.shape[0]), interpolation=cv2.INTER_AREA)    \n",
        "    \n",
        "    # Apply camera model with k(exposure ratio)\n",
        "    isBad = t_our < 0.5\n",
        "    J = maxEntropyEnhance(I, isBad)\n",
        "\n",
        "    # W: Weight Matrix\n",
        "    t = np.zeros((t_our.shape[0], t_our.shape[1], I.shape[2]))\n",
        "    for i in range(I.shape[2]):\n",
        "        t[:,:,i] = t_our\n",
        "    W = t**mu\n",
        "    \n",
        "    #fusion\n",
        "    I2 = I*W\n",
        "    J2 = J*(1-W)\n",
        "\n",
        "    result = I2 + J2\n",
        "    result = result * 255\n",
        "    result[result > 255] = 255\n",
        "    result[result<0] = 0\n",
        "    return result.astype(np.uint8)\n",
        "\n"
      ],
      "metadata": {
        "id": "btggyoSYHThn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_correction(r,u_r,u_ref,L2):\n",
        "    L1 = np.max(r)\n",
        "    gainFactor = L1 * (u_r/ u_ref) +L2\n",
        "    Out = r / gainFactor\n",
        "    return Out\n",
        "\n",
        "def OptimalParameter(sceneRadiance):\n",
        "    img = np.float64(sceneRadiance / 255)\n",
        "    b, g, r = cv2.split(img)\n",
        "\n",
        "    u_r = np.sum(r)\n",
        "    u_g = np.sum(g)\n",
        "    u_b = np.sum(b)\n",
        "    u_ref = (u_r ** 2 + u_g ** 2 + u_b ** 2) ** 0.5\n",
        "    L2 = 0.25\n",
        "    r = color_correction(r, u_r, u_ref, L2)\n",
        "    g = color_correction(g, u_g, u_ref, L2)\n",
        "    b = color_correction(b, u_b, u_ref, L2)\n",
        "\n",
        "    sceneRadiance = np.zeros((img.shape), 'float64')\n",
        "    sceneRadiance[:, :, 0] = b\n",
        "    sceneRadiance[:, :, 1] = g\n",
        "    sceneRadiance[:, :, 2] = r\n",
        "    sceneRadiance = sceneRadiance * 255\n",
        "    sceneRadiance = np.clip(sceneRadiance,0, 255)\n",
        "    sceneRadiance = np.uint8(sceneRadiance)\n",
        "    return sceneRadiance\n",
        "\n",
        "\n",
        "def simplest_cb(img, percent):\n",
        "    out_channels = []\n",
        "    channels = cv2.split(img)\n",
        "    totalstop = channels[0].shape[0] * channels[0].shape[1] * percent / 200.0\n",
        "    for channel in channels:\n",
        "        bc = cv2.calcHist([channel], [0], None, [256], (0,256), accumulate=False)\n",
        "        lv = np.searchsorted(np.cumsum(bc), totalstop)\n",
        "        hv = 255-np.searchsorted(np.cumsum(bc[::-1]), totalstop)\n",
        "        lut = np.array([0 if i < lv else (255 if i > hv else round(float(i-lv)/float(hv-lv)*255)) for i in np.arange(0, 256)], dtype=\"uint8\")\n",
        "        out_channels.append(cv2.LUT(channel, lut))\n",
        "    return cv2.merge(out_channels)\n"
      ],
      "metadata": {
        "id": "WnwyZ0toHYL0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.matlib\n",
        "\n",
        "\n",
        "\n",
        "class WBsRGB:\n",
        "    def __init__(self, gamut_mapping=2, upgraded=0):\n",
        "\n",
        "        if upgraded == 1:\n",
        "            self.features = np.load('models/features+.npy') # training encoded features\n",
        "            self.mappingFuncs = np.load('models/mappingFuncs+.npy') # mapping correction functions\n",
        "            self.encoderWeights = np.load('models/encoderWeights+.npy') # weight matrix for histogram encoding\n",
        "            self.encoderBias = np.load('models/encoderBias+.npy') # bias vector for histogram encoding\n",
        "            self.K = 75  # K value for nearest neighbor searching---for the upgraded model, we found 75 is better\n",
        "        else:\n",
        "            self.features = np.load('models/features.npy')  # training encoded features\n",
        "            self.mappingFuncs = np.load('models/mappingFuncs.npy')  # mapping correction functions\n",
        "            self.encoderWeights = np.load('models/encoderWeights.npy')  # weight matrix for histogram encoding\n",
        "            self.encoderBias = np.load('models/encoderBias.npy')  # bias vector for histogram encoding\n",
        "            self.K = 25  # K value for nearest neighbor searching\n",
        "\n",
        "        self.sigma = 0.25  # fall-off factor for KNN blending\n",
        "        self.h = 60 # histogram bin width\n",
        "        # our results reported with gamut_mapping=2, however gamut_mapping=1 gives more compelling results with\n",
        "        # over-saturated examples\n",
        "        self.gamut_mapping = gamut_mapping #options: =1 for scaling, =2 for clipping\n",
        "\n"
      ],
      "metadata": {
        "id": "_LtMjPO-HdB_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(self, hist):\n",
        "        \"\"\" Generates a compacted feature of a given RGB-uv histogram tensor. \"\"\"\n",
        "        histR_reshaped = np.reshape(np.transpose(hist[:, :, 0]),\n",
        "                       (1, int(hist.size / 3)), order=\"F\")  # reshaped red layer of histogram\n",
        "        histG_reshaped = np.reshape(np.transpose(hist[:, :, 1]),\n",
        "                                    (1, int(hist.size / 3)), order=\"F\")  # reshaped green layer of histogram\n",
        "        histB_reshaped = np.reshape(np.transpose(hist[:, :, 2]),\n",
        "                                    (1, int(hist.size / 3)), order=\"F\")  # reshaped blue layer of histogram\n",
        "        hist_reshaped = np.append(histR_reshaped,\n",
        "                                  [histG_reshaped, histB_reshaped])  # reshaped histogram n * 3 (n = h*h)\n",
        "        feature = np.dot(hist_reshaped - self.encoderBias.transpose(), self.encoderWeights)  # compute compacted histogram feature\n",
        "        return feature\n"
      ],
      "metadata": {
        "id": "AwK9BDYdHiQp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rgbUVhist(self, I):\n",
        "        \"\"\" Computes an RGB-uv histogram tensor. \"\"\"\n",
        "        sz = np.shape(I)  # get size of current image\n",
        "        if sz[0] * sz[1] > 202500:  # if it is larger than 450*450\n",
        "            factor = np.sqrt(202500 / (sz[0] * sz[1]))  # rescale factor\n",
        "            newH = int(np.floor(sz[0] * factor))\n",
        "            newW = int(np.floor(sz[1] * factor))\n",
        "            I = cv2.resize(I, (newW, newH), interpolation=cv2.INTER_NEAREST)  # resize image\n",
        "        II = I.reshape(int(I.size / 3), 3)  # n*3\n",
        "        inds = np.where((II[:, 0] > 0) & (II[:, 1] > 0) & (II[:, 2] > 0))  # remove any zero pixels\n",
        "        R = II[inds, 0]  # red channel\n",
        "        G = II[inds, 1]  # green channel\n",
        "        B = II[inds, 2]  # blue channel\n",
        "        I_reshaped = np.concatenate((R, G, B), axis=0).transpose()  # reshaped image (wo zero values)\n",
        "        eps = 6.4 / self.h\n",
        "        A = np.arange(-3.2, 3.19, eps)  # dummy vector\n",
        "        hist = np.zeros((A.size, A.size, 3))  # histogram will be stored here\n",
        "        Iy = np.sqrt(np.power(I_reshaped[:, 0], 2) + np.power(I_reshaped[:, 1], 2) +\n",
        "                     np.power(I_reshaped[:, 2], 2))  # intensity vector\n",
        "        for i in range(3):  # for each histogram layer, do\n",
        "            r = []  # excluded channels will be stored here\n",
        "            for j in range(3):  # for each color channel do\n",
        "                if j != i:  # if current color channel does not match current histogram layer,\n",
        "                    r.append(j)  # exclude it\n",
        "            Iu = np.log(I_reshaped[:, i] / I_reshaped[:, r[1]])  # current color channel / the first excluded channel\n",
        "            Iv = np.log(I_reshaped[:, i] / I_reshaped[:, r[0]])  # current color channel / the second excluded channel\n",
        "            diff_u = np.abs(np.matlib.repmat(Iu, np.size(A), 1).transpose() - np.matlib.repmat(A, np.size(Iu),\n",
        "                                                                                               1))  # differences in u space\n",
        "            diff_v = np.abs(np.matlib.repmat(Iv, np.size(A), 1).transpose() - np.matlib.repmat(A, np.size(Iv),\n",
        "                                                                                               1))  # differences in v space\n",
        "            diff_u[diff_u >= (eps / 2)] = 0  # do not count any pixel has difference beyond the threshold in the u space\n",
        "            diff_u[diff_u != 0] = 1  # remaining pixels will be counted\n",
        "            diff_v[diff_v >= (eps / 2)] = 0  # do not count any pixel has difference beyond the threshold in the v space\n",
        "            diff_v[diff_v != 0] = 1  # remaining pixels will be counted\n",
        "            # here, we will use a matrix multiplication expression to compute eq. 4 in the main paper.\n",
        "            # why? because it is much faster\n",
        "            temp = (np.matlib.repmat(Iy, np.size(A), 1) * (diff_u).transpose())  # Iy .* diff_u' (.* element-wise mult)\n",
        "            hist[:, :, i] = np.dot(temp, diff_v)  # initialize current histogram layer with Iy .* diff' * diff_v\n",
        "            norm_ = np.sum(hist[:, :, i], axis=None)  # compute sum of hist for normalization\n",
        "            hist[:, :, i] = np.sqrt(hist[:, :, i] / norm_)  # (hist/norm)^(1/2)\n",
        "        return hist\n"
      ],
      "metadata": {
        "id": "gvhfsxgVHqoi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def correctImage(self, I):\n",
        "        \"\"\" White balance a given image I. \"\"\"\n",
        "        I = cv2.cvtColor(I, cv2.COLOR_BGR2RGB)  # convert from BGR to RGB\n",
        "        I = im2double(I)  # convert to double\n",
        "        feature = self.encode(self.rgbUVhist(I))\n",
        "        D_sq = np.einsum('ij, ij ->i', self.features, self.features)[:, None] + \\\n",
        "               np.einsum('ij, ij ->i', feature, feature) - \\\n",
        "               2 * self.features.dot(feature.T)  # squared euclidean distances\n",
        "\n",
        "        idH = D_sq.argpartition(self.K, axis=0)[:self.K]  # get smallest K distances\n",
        "        mappingFuncs = np.squeeze(self.mappingFuncs[idH, :])\n",
        "        dH = np.sqrt(\n",
        "            np.take_along_axis(D_sq, idH, axis=0))  # square root nearest distances to get real euclidean distances\n",
        "        sorted_idx = dH.argsort(axis=0)  # get sorting indices\n",
        "        idH = np.take_along_axis(idH, sorted_idx, axis=0)  # sort distance indices\n",
        "        dH = np.take_along_axis(dH, sorted_idx, axis=0)  # sort distances\n",
        "        weightsH = np.exp(-(np.power(dH, 2)) /\n",
        "                          (2 * np.power(self.sigma, 2)))  # compute blending weights\n",
        "        weightsH = weightsH / sum(weightsH)  # normalize blending weights\n",
        "        mf = sum(np.matlib.repmat(weightsH, 1, 33) *\n",
        "                 mappingFuncs, 0)  # compute the mapping function\n",
        "        mf = mf.reshape(11, 3, order=\"F\")  # reshape it to be 9 * 3\n",
        "        I_corr = self.colorCorrection(I, mf) # apply it!\n",
        "        return I_corr\n",
        "\n",
        "    def colorCorrection(self, input, m):\n",
        "        \"\"\" Applies a mapping function m to a given input image. \"\"\"\n",
        "        sz = np.shape(input) # get size of input image\n",
        "        I_reshaped = np.reshape(input,(int(input.size/3),3),\n",
        "                                order=\"F\") # reshape input to be n*3 (n: total number of pixels)\n",
        "        kernel_out = kernelP(I_reshaped) # raise input image to a higher-dim space\n",
        "        out = np.dot(kernel_out, m) # apply m to the input image after raising it the selected higher degree\n",
        "        if self.gamut_mapping == 1:\n",
        "            out = normScaling(I_reshaped, out) # scaling based on input image energy\n",
        "        elif self.gamut_mapping == 2:\n",
        "            out = outOfGamutClipping(out) # clip out-of-gamut pixels\n",
        "        else:\n",
        "            raise Exception('Wrong gamut_mapping value')\n",
        "        out = out.reshape(sz[0], sz[1], sz[2], order=\"F\")  # reshape output image back to the original image shape\n",
        "        out = cv2.cvtColor(out.astype('float32'), cv2.COLOR_RGB2BGR)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "DZWn9_pXHs7H"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normScaling(I, I_corr):\n",
        "    \"\"\" Scales each pixel based on original image energy. \"\"\"\n",
        "    norm_I_corr = np.sqrt(np.sum(np.power(I_corr, 2), 1))\n",
        "    inds = norm_I_corr != 0\n",
        "    norm_I_corr = norm_I_corr[inds]\n",
        "    norm_I = np.sqrt(np.sum(np.power(I[inds, :],2), 1))\n",
        "    I_corr[inds, :] = I_corr[inds, :]/np.tile(norm_I_corr[:, np.newaxis], 3) * \\\n",
        "                      np.tile(norm_I[:, np.newaxis], 3)\n",
        "    return I_corr\n",
        "\n",
        "\n",
        "def kernelP(I):\n",
        "    \"\"\" Kernel function: kernel(r, g, b) -> (r,g,b,rg,rb,gb,r^2,g^2,b^2,rgb,1)\n",
        "        Ref: Hong, et al., \"A study of digital camera colorimetric characterization\n",
        "         based on polynomial modeling.\" Color Research & Application, 2001. \"\"\"\n",
        "    return (np.transpose((I[:,0], I[:,1], I[:,2], I[:,0] * I[:,1], I[:,0] * I[:,2],\n",
        "                          I[:,1] * I[:,2], I[:, 0] * I[:, 0], I[:, 1] * I[:, 1],\n",
        "                          I[:, 2] * I[:, 2], I[:, 0] * I[:, 1] * I[:, 2],\n",
        "                          np.repeat(1,np.shape(I)[0]))))\n"
      ],
      "metadata": {
        "id": "g9Ym_vYqH3BJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def outOfGamutClipping(I):\n",
        "    \"\"\" Clips out-of-gamut pixels. \"\"\"\n",
        "    I[I > 1] = 1 # any pixel is higher than 1, clip it to 1\n",
        "    I[I < 0] = 0 # any pixel is below 0, clip it to 0\n",
        "    return I\n",
        "\n",
        "def im2double(im):\n",
        "    \"\"\" Returns a double image [0,1] of the uint8 im [0,255]. \"\"\"\n",
        "    return cv2.normalize(im.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "import numpy as np\n",
        "import numpy.matlib\n"
      ],
      "metadata": {
        "id": "AmQQzRk7H8i8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WBsRGB:\n",
        "    def __init__(self, gamut_mapping=2, upgraded=0):\n",
        "\n",
        "        if upgraded == 1:\n",
        "            self.features = np.load('models/features+.npy') # training encoded features\n",
        "            self.mappingFuncs = np.load('models/mappingFuncs+.npy') # mapping correction functions\n",
        "            self.encoderWeights = np.load('models/encoderWeights+.npy') # weight matrix for histogram encoding\n",
        "            self.encoderBias = np.load('models/encoderBias+.npy') # bias vector for histogram encoding\n",
        "            self.K = 75  # K value for nearest neighbor searching---for the upgraded model, we found 75 is better\n",
        "        else:\n",
        "            self.features = np.load('models/features.npy')  # training encoded features\n",
        "            self.mappingFuncs = np.load('models/mappingFuncs.npy')  # mapping correction functions\n",
        "            self.encoderWeights = np.load('models/encoderWeights.npy')  # weight matrix for histogram encoding\n",
        "            self.encoderBias = np.load('models/encoderBias.npy')  # bias vector for histogram encoding\n",
        "            self.K = 25  # K value for nearest neighbor searching\n",
        "\n",
        "        self.sigma = 0.25  # fall-off factor for KNN blending\n",
        "        self.h = 60 # histogram bin width\n",
        "        # our results reported with gamut_mapping=2, however gamut_mapping=1 gives more compelling results with\n",
        "        # over-saturated examples\n",
        "        self.gamut_mapping = gamut_mapping #options: =1 for scaling, =2 for clipping\n"
      ],
      "metadata": {
        "id": "BS2KM1IqIAfG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(self, hist):\n",
        "        \"\"\" Generates a compacted feature of a given RGB-uv histogram tensor. \"\"\"\n",
        "        histR_reshaped = np.reshape(np.transpose(hist[:, :, 0]),\n",
        "                       (1, int(hist.size / 3)), order=\"F\")  # reshaped red layer of histogram\n",
        "        histG_reshaped = np.reshape(np.transpose(hist[:, :, 1]),\n",
        "                                    (1, int(hist.size / 3)), order=\"F\")  # reshaped green layer of histogram\n",
        "        histB_reshaped = np.reshape(np.transpose(hist[:, :, 2]),\n",
        "                                    (1, int(hist.size / 3)), order=\"F\")  # reshaped blue layer of histogram\n",
        "        hist_reshaped = np.append(histR_reshaped,\n",
        "                                  [histG_reshaped, histB_reshaped])  # reshaped histogram n * 3 (n = h*h)\n",
        "        feature = np.dot(hist_reshaped - self.encoderBias.transpose(), self.encoderWeights)  # compute compacted histogram feature\n",
        "        return feature\n"
      ],
      "metadata": {
        "id": "25wM8nmHIE_C"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def rgbUVhist(self, I):\n",
        "        \"\"\" Computes an RGB-uv histogram tensor. \"\"\"\n",
        "        sz = np.shape(I)  # get size of current image\n",
        "        if sz[0] * sz[1] > 202500:  # if it is larger than 450*450\n",
        "            factor = np.sqrt(202500 / (sz[0] * sz[1]))  # rescale factor\n",
        "            newH = int(np.floor(sz[0] * factor))\n",
        "            newW = int(np.floor(sz[1] * factor))\n",
        "            I = cv2.resize(I, (newW, newH), interpolation=cv2.INTER_NEAREST)  # resize image\n",
        "        II = I.reshape(int(I.size / 3), 3)  # n*3\n",
        "        inds = np.where((II[:, 0] > 0) & (II[:, 1] > 0) & (II[:, 2] > 0))  # remove any zero pixels\n",
        "        R = II[inds, 0]  # red channel\n",
        "        G = II[inds, 1]  # green channel\n",
        "        B = II[inds, 2]  # blue channel\n",
        "        I_reshaped = np.concatenate((R, G, B), axis=0).transpose()  # reshaped image (wo zero values)\n",
        "        eps = 6.4 / self.h\n",
        "        A = np.arange(-3.2, 3.19, eps)  # dummy vector\n",
        "        hist = np.zeros((A.size, A.size, 3))  # histogram will be stored here\n",
        "        Iy = np.sqrt(np.power(I_reshaped[:, 0], 2) + np.power(I_reshaped[:, 1], 2) +\n",
        "                     np.power(I_reshaped[:, 2], 2))  # intensity vector\n",
        "        for i in range(3):  # for each histogram layer, do\n",
        "            r = []  # excluded channels will be stored here\n",
        "            for j in range(3):  # for each color channel do\n",
        "                if j != i:  # if current color channel does not match current histogram layer,\n",
        "                    r.append(j)  # exclude it\n",
        "            Iu = np.log(I_reshaped[:, i] / I_reshaped[:, r[1]])  # current color channel / the first excluded channel\n",
        "            Iv = np.log(I_reshaped[:, i] / I_reshaped[:, r[0]])  # current color channel / the second excluded channel\n",
        "            diff_u = np.abs(np.matlib.repmat(Iu, np.size(A), 1).transpose() - np.matlib.repmat(A, np.size(Iu),\n",
        "                                                                                               1))  # differences in u space\n",
        "            diff_v = np.abs(np.matlib.repmat(Iv, np.size(A), 1).transpose() - np.matlib.repmat(A, np.size(Iv),\n",
        "                                                                                               1))  # differences in v space\n",
        "            diff_u[diff_u >= (eps / 2)] = 0  # do not count any pixel has difference beyond the threshold in the u space\n",
        "            diff_u[diff_u != 0] = 1  # remaining pixels will be counted\n",
        "            diff_v[diff_v >= (eps / 2)] = 0  # do not count any pixel has difference beyond the threshold in the v space\n",
        "            diff_v[diff_v != 0] = 1  # remaining pixels will be counted\n",
        "            # here, we will use a matrix multiplication expression to compute eq. 4 in the main paper.\n",
        "            # why? because it is much faster\n",
        "            temp = (np.matlib.repmat(Iy, np.size(A), 1) * (diff_u).transpose())  # Iy .* diff_u' (.* element-wise mult)\n",
        "            hist[:, :, i] = np.dot(temp, diff_v)  # initialize current histogram layer with Iy .* diff' * diff_v\n",
        "            norm_ = np.sum(hist[:, :, i], axis=None)  # compute sum of hist for normalization\n",
        "            hist[:, :, i] = np.sqrt(hist[:, :, i] / norm_)  # (hist/norm)^(1/2)\n",
        "        return hist\n"
      ],
      "metadata": {
        "id": "jAq_8McmIMVA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def correctImage(self, I):\n",
        "        \"\"\" White balance a given image I. \"\"\"\n",
        "        I = cv2.cvtColor(I, cv2.COLOR_BGR2RGB)  # convert from BGR to RGB\n",
        "        I = im2double(I)  # convert to double\n",
        "        feature = self.encode(self.rgbUVhist(I))\n",
        "        D_sq = np.einsum('ij, ij ->i', self.features, self.features)[:, None] + \\\n",
        "               np.einsum('ij, ij ->i', feature, feature) - \\\n",
        "               2 * self.features.dot(feature.T)  # squared euclidean distances\n",
        "\n",
        "        idH = D_sq.argpartition(self.K, axis=0)[:self.K]  # get smallest K distances\n",
        "        mappingFuncs = np.squeeze(self.mappingFuncs[idH, :])\n",
        "        dH = np.sqrt(\n",
        "            np.take_along_axis(D_sq, idH, axis=0))  # square root nearest distances to get real euclidean distances\n",
        "        sorted_idx = dH.argsort(axis=0)  # get sorting indices\n",
        "        idH = np.take_along_axis(idH, sorted_idx, axis=0)  # sort distance indices\n",
        "        dH = np.take_along_axis(dH, sorted_idx, axis=0)  # sort distances\n",
        "        weightsH = np.exp(-(np.power(dH, 2)) /\n",
        "                          (2 * np.power(self.sigma, 2)))  # compute blending weights\n",
        "        weightsH = weightsH / sum(weightsH)  # normalize blending weights\n",
        "        mf = sum(np.matlib.repmat(weightsH, 1, 33) *\n",
        "                 mappingFuncs, 0)  # compute the mapping function\n",
        "        mf = mf.reshape(11, 3, order=\"F\")  # reshape it to be 9 * 3\n",
        "        I_corr = self.colorCorrection(I, mf) # apply it!\n",
        "        return I_corr\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8shtA9-ITXa"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    \n",
        "\n",
        "def normScaling(I, I_corr):\n",
        "    \"\"\" Scales each pixel based on original image energy. \"\"\"\n",
        "    norm_I_corr = np.sqrt(np.sum(np.power(I_corr, 2), 1))\n",
        "    inds = norm_I_corr != 0\n",
        "    norm_I_corr = norm_I_corr[inds]\n",
        "    norm_I = np.sqrt(np.sum(np.power(I[inds, :],2), 1))\n",
        "    I_corr[inds, :] = I_corr[inds, :]/np.tile(norm_I_corr[:, np.newaxis], 3) * \\\n",
        "                      np.tile(norm_I[:, np.newaxis], 3)\n",
        "    return I_corr\n",
        "\n",
        "\n",
        "def kernelP(I):\n",
        "    \"\"\" Kernel function: kernel(r, g, b) -> (r,g,b,rg,rb,gb,r^2,g^2,b^2,rgb,1)\n",
        "        Ref: Hong, et al., \"A study of digital camera colorimetric characterization\n",
        "         based on polynomial modeling.\" Color Research & Application, 2001. \"\"\"\n",
        "    return (np.transpose((I[:,0], I[:,1], I[:,2], I[:,0] * I[:,1], I[:,0] * I[:,2],\n",
        "                          I[:,1] * I[:,2], I[:, 0] * I[:, 0], I[:, 1] * I[:, 1],\n",
        "                          I[:, 2] * I[:, 2], I[:, 0] * I[:, 1] * I[:, 2],\n",
        "                          np.repeat(1,np.shape(I)[0]))))\n",
        "\n",
        "def outOfGamutClipping(I):\n",
        "    \"\"\" Clips out-of-gamut pixels. \"\"\"\n",
        "    I[I > 1] = 1 # any pixel is higher than 1, clip it to 1\n",
        "    I[I < 0] = 0 # any pixel is below 0, clip it to 0\n",
        "    return I\n",
        "\n",
        "def im2double(im):\n",
        "    \"\"\" Returns a double image [0,1] of the uint8 im [0,255]. \"\"\"\n",
        "    return cv2.normalize(im.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n"
      ],
      "metadata": {
        "id": "FfMTM2xIIUoN"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}